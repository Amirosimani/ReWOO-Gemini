{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "dpldCVg60L9c",
        "bR8zNLEA0g5_"
      ],
      "authorship_tag": "ABX9TyP9YlohmmzJDmDElsbAdm/Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amirosimani/ReWOO-Gemini/blob/main/ReWOO_gemini.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install --quiet datasets\n",
        "# !pip install --quiet langchain langchain_community\n",
        "# !pip install --quiet langchain_google_genai langchain_google_community\n",
        "# !pip install --quiet wikipedia\n",
        "# !pip install --quiet tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_In1NIeyqmD2",
        "outputId": "f56c046f-cf4d-4241-bd44-305c54067838"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/1.2 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "9a055BpR5zkn"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Configuration ---\n",
        "MODEL = \"gemini-1.5-flash\"\n",
        "MAX_ITERATIONS = 10\n",
        "MAX_EXECUTION_TIME = 90\n",
        "\n",
        "GENERATION_CONFIG = {\n",
        "    \"temperature\": 0.8,\n",
        "    \"top_p\": 0.95,\n",
        "    \"top_k\": 20,\n",
        "    \"candidate_count\": 1,\n",
        "    \"max_output_tokens\": 8192,\n",
        "    \"stop_sequences\": [\"STOP!\"],\n",
        "}\n",
        "\n",
        "# SAFETY_SETTINGS = {\n",
        "#     HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "#     HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "#     HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "#     HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "# }\n",
        "\n",
        "\n",
        "GEMINI_API_KEY = userdata.get('GEMINI')\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE-API')\n",
        "CSE_ID = userdata.get(\"CSE-ID\")"
      ],
      "metadata": {
        "id": "MRqm03Sz5_fF"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data\n",
        "\n",
        "[**StrategyQA**](https://paperswithcode.com/dataset/strategyqa) is a question answering benchmark where the required reasoning steps are implicit in the question, and should be inferred using a strategy. It includes 2,780 examples, each consisting of a strategy question, its decomposition, and evidence paragraphs. Questions in StrategyQA are short, topic-diverse, and cover a wide range of strategies.\n",
        "\n"
      ],
      "metadata": {
        "id": "pQxf0kNGBtVN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfevMoHIBgbP",
        "outputId": "1aafa218-2662-4062-aae0-6e2b87d2d3ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"ChilleD/StrategyQA\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Access the training split\n",
        "train_ds = ds[\"train\"]"
      ],
      "metadata": {
        "id": "3nXOp5QCCMxp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kPIwj4Ew-qQ",
        "outputId": "c64034cc-73dc-48b0-c967-bf299d304f7a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'qid': '4fd64bb6ce5b78ab20b6',\n",
              " 'term': 'Mixed martial arts',\n",
              " 'description': 'full contact combat sport',\n",
              " 'question': 'Is Mixed martial arts totally original from Roman Colosseum games?',\n",
              " 'answer': False,\n",
              " 'facts': 'Mixed Martial arts in the UFC takes place in an enclosed structure called The Octagon. The Roman Colosseum games were fought in enclosed arenas where combatants would fight until the last man was standing. Mixed martial arts contests are stopped when one of the combatants is incapacitated. The Roman Colosseum was performed in front of crowds that numbered in the tens of thousands. Over 56,000 people attended UFC 193.'}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LLM"
      ],
      "metadata": {
        "id": "2ceIKSwrsu2W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline"
      ],
      "metadata": {
        "id": "dpldCVg60L9c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "from google.genai.types import GenerateContentConfig"
      ],
      "metadata": {
        "id": "Cf8Xn9ia0Lf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = genai.Client(api_key=GEMINI_API_KEY)"
      ],
      "metadata": {
        "id": "daCJHjFf5rAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(prompt, model=MODEL, config=GENERATION_CONFIG):\n",
        "\n",
        "    response = client.models.generate_content(\n",
        "        model=model,\n",
        "        contents=prompt,\n",
        "        config=GenerateContentConfig(**config)\n",
        "    )\n",
        "    return response"
      ],
      "metadata": {
        "id": "aJKvz8tz0tql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate(prompt=train_ds[0]['question'])"
      ],
      "metadata": {
        "id": "RGznz1Wd0f3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response.usage_metadata.total_token_count"
      ],
      "metadata": {
        "id": "5YvBz9PwnYls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# output_filename = \"./output/combined_responses.json\"  # Single output file\n",
        "# all_responses = []  # List to store all responses\n",
        "\n",
        "# # Create the output directory if it doesn't exist\n",
        "# os.makedirs(\"./output\", exist_ok=True)\n",
        "\n",
        "# for i in range(train_ds.shape[0]):\n",
        "#     response = generate(prompt=train_ds[i]['question'])\n",
        "\n",
        "#     serializable_response = {}\n",
        "#     try:\n",
        "#         serializable_response = {\"text\": response.text,\n",
        "#                                  \"total_token\": response.usage_metadata.total_token_count}\n",
        "#     except AttributeError:\n",
        "#         try:\n",
        "#             serializable_response = response.to_dict()\n",
        "#         except AttributeError:\n",
        "#             serializable_response = str(response)  # fallback\n",
        "\n",
        "#     all_responses.append(serializable_response)  # Add to the list of all responses\n",
        "\n",
        "#     # Save ALL responses to the single file after EACH iteration\n",
        "#     with open(output_filename, \"w\", encoding=\"utf-8\") as f:\n",
        "#         json.dump(all_responses, f, indent=4, ensure_ascii=False)\n",
        "\n",
        "#     time.sleep(2)\n",
        "#     print(f\"Saved responses to {output_filename} (Iteration {i+1} of {train_ds.shape[0]})\")\n",
        "\n",
        "# print(\"Loop finished.\")\n"
      ],
      "metadata": {
        "id": "w1WkVXyVNaUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Native tool call"
      ],
      "metadata": {
        "id": "bR8zNLEA0g5_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "from google.genai.types import GenerateContentConfig"
      ],
      "metadata": {
        "id": "kPHYEqYiKn_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def generate(prompt, model=MODEL, config=GENERATION_CONFIG):\n",
        "#     response = client.models.generate_content(\n",
        "#         model=model,\n",
        "#         contents=prompt,\n",
        "#         config=GenerateContentConfig(**config),\n",
        "#         # tools='google_search_retrieval'\n",
        "#     )\n",
        "#     return response"
      ],
      "metadata": {
        "id": "tNvj9QwUKfZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate(prompt=train_ds[0]['question'])"
      ],
      "metadata": {
        "id": "QI184a6FKvp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ReAct Agent"
      ],
      "metadata": {
        "id": "JkMOsPAp0KMQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from typing import List, Dict, Union, Callable\n",
        "\n",
        "import tiktoken\n",
        "from langchain import hub\n",
        "from langchain.agents import AgentExecutor, create_react_agent\n",
        "from langchain_community.utilities import GoogleSearchAPIWrapper, WikipediaAPIWrapper\n",
        "from langchain.callbacks.base import BaseCallbackHandler\n",
        "from langchain.schema import AgentAction, AgentFinish, LLMResult, BaseMessage\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI, HarmBlockThreshold, HarmCategory\n",
        "from langchain.tools import Tool"
      ],
      "metadata": {
        "id": "NeBirELxHeM6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ReActAgentExecutor:\n",
        "    \"\"\"\n",
        "    A class to run the ReAct agent with specified configurations and tools.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        model: str = MODEL,\n",
        "        generation_config: Dict = GENERATION_CONFIG,\n",
        "        # safety_settings: Dict = SAFETY_SETTINGS,\n",
        "        max_iterations: int = MAX_ITERATIONS,\n",
        "        max_execution_time: int = MAX_EXECUTION_TIME,\n",
        "        google_api_key: str = GOOGLE_API_KEY,\n",
        "        cse_id: str = CSE_ID,\n",
        "    ):\n",
        "        self.model = model\n",
        "        self.generation_config = generation_config\n",
        "        # self.safety_settings = safety_settings\n",
        "        self.max_iterations = max_iterations\n",
        "        self.max_execution_time = max_execution_time\n",
        "        self.google_api_key = google_api_key\n",
        "        self.cse_id = cse_id\n",
        "        self.llm = None\n",
        "        self.tools = None\n",
        "        self.agent = None\n",
        "        self.agent_executor = None\n",
        "        self.token_callback = None\n",
        "\n",
        "        self._setup_llm()\n",
        "        self._setup_tools()\n",
        "        self._setup_agent()\n",
        "\n",
        "    def _setup_llm(self):\n",
        "      \"\"\"Initializes the language model.\"\"\"\n",
        "      if not GEMINI_API_KEY or GEMINI_API_KEY == \"your_gemini_api_key\":\n",
        "          raise ValueError(\"GEMINI_API_KEY must be set to a valid API key.\")\n",
        "      self.llm = ChatGoogleGenerativeAI(\n",
        "          model=self.model,\n",
        "          google_api_key=GEMINI_API_KEY,\n",
        "          generation_config=self.generation_config,\n",
        "          # safety_settings=self.safety_settings,\n",
        "      )\n",
        "\n",
        "    def _setup_tools(self):\n",
        "        \"\"\"Sets up the tools for the agent.\"\"\"\n",
        "        search = GoogleSearchAPIWrapper(\n",
        "            google_api_key=self.google_api_key, google_cse_id=self.cse_id\n",
        "        )\n",
        "        wikipedia = WikipediaAPIWrapper(top_k_results=3, doc_content_chars_max=1000)\n",
        "\n",
        "        self.tools = [\n",
        "            Tool(\n",
        "                name=\"Google Search\",\n",
        "                func=search.run,\n",
        "                description=\"Useful for finding information on current events, comparisons, or diverse perspectives.\",\n",
        "            ),\n",
        "            Tool(\n",
        "                name=\"Wikipedia\",\n",
        "                func=wikipedia.run,\n",
        "                description=\"Useful for getting definitions and summaries of topics from Wikipedia.\",\n",
        "            ),\n",
        "        ]\n",
        "\n",
        "    def _setup_agent(self):\n",
        "        \"\"\"Sets up the ReAct agent and executor.\"\"\"\n",
        "        prompt = hub.pull(\"hwchase17/react\")\n",
        "        self.agent = create_react_agent(self.llm, self.tools, prompt)\n",
        "\n",
        "        self.token_callback = TokenCountingCallbackHandler(self.model)\n",
        "        self.agent_executor = AgentExecutor(\n",
        "            agent=self.agent,\n",
        "            tools=self.tools,\n",
        "            verbose=False,\n",
        "            handle_parsing_errors=True,\n",
        "            max_iterations=self.max_iterations,\n",
        "            max_execution_time=self.max_execution_time,\n",
        "            callbacks=[self.token_callback],\n",
        "        )\n",
        "\n",
        "    def run(self, input_data: Union[Dict, str]) -> Dict:\n",
        "        \"\"\"\n",
        "        Runs the agent with the given input data.\n",
        "\n",
        "        Args:\n",
        "            input_data: Either a dictionary or a string representing the input for the agent.\n",
        "\n",
        "        Returns:\n",
        "            The output from the agent.\n",
        "        \"\"\"\n",
        "        if isinstance(input_data, str):\n",
        "            input_data = {\"input\": input_data}\n",
        "\n",
        "        try:\n",
        "            result = self.agent_executor.invoke(input_data)\n",
        "            # Include token usage information in the result\n",
        "            result[\"token_usage\"] = {\n",
        "                \"total_tokens\": self.token_callback.total_tokens,\n",
        "                \"prompt_tokens\": self.token_callback.prompt_tokens,\n",
        "                \"completion_tokens\": self.token_callback.completion_tokens,\n",
        "            }\n",
        "            self.token_callback.reset()  # Reset after each run\n",
        "            return result\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred: {e}\")\n",
        "            return {\"error\": str(e)}\n",
        "\n",
        "\n",
        "class TokenCountingCallbackHandler(BaseCallbackHandler):\n",
        "    \"\"\"Callback handler for counting tokens used by the language model.\"\"\"\n",
        "\n",
        "    def __init__(self, model_name: str):\n",
        "        self.model_name = model_name\n",
        "        self.total_tokens = 0\n",
        "        self.prompt_tokens = 0\n",
        "        self.completion_tokens = 0\n",
        "        self.encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
        "\n",
        "    def on_llm_start(\n",
        "        self, serialized: Dict[str, any], prompts: List[str], **kwargs\n",
        "    ) -> None:\n",
        "        \"\"\"Collect prompt tokens when LLM starts.\"\"\"\n",
        "        for prompt in prompts:\n",
        "            self.prompt_tokens += len(self.encoding.encode(prompt))\n",
        "\n",
        "    def on_llm_end(self, response: LLMResult, **kwargs) -> None:\n",
        "        \"\"\"Collect completion tokens when LLM finishes generating.\"\"\"\n",
        "        if response.generations:\n",
        "            for generation_list in response.generations:\n",
        "                for generation in generation_list:\n",
        "                    if generation.text:\n",
        "                        self.completion_tokens += len(\n",
        "                            self.encoding.encode(generation.text)\n",
        "                        )\n",
        "\n",
        "    def on_agent_action(self, action: AgentAction, **kwargs) -> None:\n",
        "        \"\"\"Increment token count on agent action.\"\"\"\n",
        "        if action.log:\n",
        "            self.total_tokens += len(self.encoding.encode(action.log))\n",
        "\n",
        "    def on_agent_finish(self, finish: AgentFinish, **kwargs) -> None:\n",
        "        \"\"\"Increment token count on agent finish.\"\"\"\n",
        "        if finish.log:\n",
        "            self.total_tokens += len(self.encoding.encode(finish.log))\n",
        "\n",
        "    def on_chain_end(self, outputs, **kwargs) -> None:\n",
        "        \"\"\"Print the total tokens used when the chain finishes.\"\"\"\n",
        "        self.total_tokens += self.completion_tokens + self.prompt_tokens\n",
        "        print(f\"Prompt tokens: {self.prompt_tokens}\")\n",
        "        print(f\"Completion tokens: {self.completion_tokens}\")\n",
        "        print(f\"Total tokens used in this chain: {self.total_tokens}\")\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"Reset the counters for the next chain run.\"\"\"\n",
        "        self.total_tokens = 0\n",
        "        self.prompt_tokens = 0\n",
        "        self.completion_tokens = 0"
      ],
      "metadata": {
        "id": "XhDsoEW8Hfxl"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# agent_executor = ReActAgentExecutor()\n",
        "# result = agent_executor.run(train_ds[0][\"question\"])"
      ],
      "metadata": {
        "id": "dNmyUg2nH8nM"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "output_filename=\"agent_results.jsonl\"\n",
        "agent_executor = ReActAgentExecutor()\n",
        "\n",
        "all_results = []\n",
        "\n",
        "for i, question in enumerate(train_ds[\"question\"]):\n",
        "    print(f\"Running agent for question {i+1}: {question}\")\n",
        "    result = agent_executor.run(question)\n",
        "    print(f\"Result for question {i+1}: {result}\")\n",
        "\n",
        "    all_results.append(\n",
        "        {\"question\": question, \"result\": result}\n",
        "    )\n",
        "\n",
        "    # Save the updated list to the file after each iteration\n",
        "    with open(output_filename, \"w\") as f:\n",
        "        for item in all_results:\n",
        "            f.write(json.dumps(item) + \"\\n\")\n",
        "\n",
        "    print(f\"Results for question {i+1} saved to {output_filename}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIqiODo1ImD-",
        "outputId": "2b33d364-30a7-4370-9ce1-baa7d00bdb65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langsmith/client.py:253: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running agent for question 1: Is Mixed martial arts totally original from Roman Colosseum games?\n",
            "Prompt tokens: 0\n",
            "Completion tokens: 0\n",
            "Total tokens used in this chain: 504\n",
            "Result for question 1: {'input': 'Is Mixed martial arts totally original from Roman Colosseum games?', 'output': \"No, mixed martial arts is not totally original from Roman Colosseum games. While both involved combat, MMA's development is rooted in 20th-century martial arts traditions, not directly connected to the fighting styles of the Roman Colosseum.\", 'token_usage': {'total_tokens': 504, 'prompt_tokens': 0, 'completion_tokens': 0}}\n",
            "Results for question 1 saved to agent_results.jsonl\n",
            "Running agent for question 2: Is the cuisine of Hawaii suitable for a vegan?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
            "\n",
            "The code that caused this warning is on line 389 of the file /usr/local/lib/python3.11/dist-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
            "\n",
            "  lis = BeautifulSoup(html).find_all('li')\n",
            "/usr/local/lib/python3.11/dist-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
            "\n",
            "The code that caused this warning is on line 389 of the file /usr/local/lib/python3.11/dist-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
            "\n",
            "  lis = BeautifulSoup(html).find_all('li')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt tokens: 0\n",
            "Completion tokens: 0\n",
            "Total tokens used in this chain: 297\n",
            "Result for question 2: {'input': 'Is the cuisine of Hawaii suitable for a vegan?', 'output': 'While traditional Hawaiian cuisine is not inherently vegan, there are many vegan options available, both as adaptations of existing dishes and as entirely new creations.  Many restaurants offer vegan versions of popular Hawaiian foods, and numerous recipes are available online and in cookbooks.  Therefore, Hawaiian cuisine can be suitable for a vegan, with some adjustments or choices.', 'token_usage': {'total_tokens': 297, 'prompt_tokens': 0, 'completion_tokens': 0}}\n",
            "Results for question 2 saved to agent_results.jsonl\n",
            "Running agent for question 3: Is capturing giant squid in natural habitat impossible with no gear?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TODO:\n",
        "\n",
        "[x] add baseline\n",
        "\n",
        "[] add calc (optional)\n",
        "\n",
        "[x] callback/count tokens for react\n",
        "\n",
        "[] ReWOO\n",
        "\n",
        "[] add everything to a class, run queries at concurrently"
      ],
      "metadata": {
        "id": "6AJANtdgltx6"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SK_KVwBw9EJA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}